{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1c6aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None) #to display full text in df'S\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from openpyxl import Workbook\n",
    "from ipywidgets import interactive\n",
    "import ipywidgets as widgets\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import boxcox\n",
    "from scipy import stats\n",
    "pd.options.display.max_rows = 50\n",
    "pd.options.display.max_columns = 999\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1a36325",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data cleaning /handling NaNs / bucketing /handling outliers\n",
    "\n",
    "\n",
    "def clean_data(df):\n",
    "    df.columns=[e.lower().replace(' ', '_') for e in df.columns] #all columns in lower case and with _\n",
    "    \n",
    "    # 'select' is a placehholder and needs to be treated like NaN\n",
    "    df.replace('Select', np.NaN, inplace =True)\n",
    "    \n",
    "    #dropping cloumns with > 30% nulls\n",
    "    #missing_value_df = df.isnull()\n",
    "    percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "    missing_value_df = pd.DataFrame({'column_name': df.columns,\n",
    "                                     'percent_missing': percent_missing})\n",
    "    missing_data_30 = list(missing_value_df[missing_value_df['percent_missing']>30]['column_name'])\n",
    "    df.drop(columns=missing_data_30, inplace= True)\n",
    "    \n",
    "    # replacement with median to deal with the ouliers\n",
    "    df['totalvisits'].fillna(df['totalvisits'].median(),inplace=True)\n",
    "    df['page_views_per_visit'].fillna(df['page_views_per_visit'].median(),inplace=True)\n",
    "    \n",
    "    #using the most frequent method to fill values\n",
    "    #df.last_activity.replace(np.NaN, 'Email Opened', inplace =True)\n",
    "    df.lead_source.replace(np.NaN, 'Google', inplace =True)\n",
    "    \n",
    "    #bucketing marked spam as unsubscribed\n",
    "    df.lead_source.replace('Email Marked Spam','Unsubscribed', inplace = True)\n",
    "    df.last_notable_activity.replace('Email Marked Spam','Unsubscribed', inplace = True)\n",
    "    \n",
    "    #bucketing values < 30 to 'Other'\n",
    "    df.last_activity.replace(('Approached upfront','View in browser link Clicked','Email Received','Email Marked Spam','Visited Booth in Tradeshow','Resubscribed to emails'), 'Other', inplace = True)\n",
    "    df.lead_source.replace(('bing','google','blog','Payoer Click Ads','Social Media','WeLearn','Click2call','Live Chat','welearnblog_Home','youtubechannel','testone','Press_Release','NC_EDM', 'Pay per Click Ads'), 'Other', inplace = True)\n",
    "    df.last_notable_activity.replace(('Had a Phone Conversation','Approached upfront','Resubscribed to emails','View in browser link Clicked','Form Submitted on Website','Email Received'), 'Other', inplace = True)\n",
    "    # bucket buisnessman and working professional \n",
    "    df.what_is_your_current_occupation.replace('Businessman', 'Working Professional', inplace =True)\n",
    "    #bucketing add forms\n",
    "    df.lead_origin.replace(('Quick Add Form','Lead Add Form'),'Add Form', inplace =True)\n",
    "    #bucketing email bounced and unreachable\n",
    "    df.last_notable_activity.replace('Email Bounced','Unreachable', inplace = True)\n",
    "    \n",
    "    # as NaN can be seen equal to other (not known), I will replace NaN's with 'Other' in occupation\n",
    "    df.what_is_your_current_occupation.replace(np.NaN, 'Other', inplace =True)\n",
    "    df.what_matters_most_to_you_in_choosing_a_course.replace(np.NaN, 'Other', inplace =True)\n",
    "    \n",
    "    \n",
    "    #drop column which is just for identification\n",
    "    df.drop(columns = 'prospect_id', inplace =True)\n",
    "    \n",
    "    \n",
    "    #drop columns which have no or little variance\n",
    "    df.drop(columns = 'country', inplace =True) #A/B testing\n",
    "    df.drop(columns = 'search', inplace =True) #A/B testing\n",
    "    df.drop(columns = 'what_matters_most_to_you_in_choosing_a_course', inplace =True)\n",
    "    df.drop(columns = 'magazine', inplace =True)\n",
    "    df.drop(columns = 'newspaper_article', inplace =True)\n",
    "    df.drop(columns = 'x_education_forums', inplace =True)\n",
    "    df.drop(columns = 'newspaper', inplace =True)\n",
    "    df.drop(columns = 'digital_advertisement', inplace =True)\n",
    "    df.drop(columns = 'through_recommendations', inplace =True)\n",
    "    df.drop(columns = 'receive_more_updates_about_our_courses', inplace =True)\n",
    "    df.drop(columns = 'get_updates_on_dm_content', inplace =True)\n",
    "    df.drop(columns = 'i_agree_to_pay_the_amount_through_cheque', inplace =True)\n",
    "    df.drop(columns = 'update_me_on_supply_chain_content', inplace = True)\n",
    "    df.drop(columns = 'do_not_call', inplace = True)\n",
    "    \n",
    "    #treating outliers with z scorre > 3\n",
    "    z = np.abs(stats.zscore(df.page_views_per_visit))\n",
    "    threshold = 5\n",
    "    outliers_pagevisits =(np.where(z > 3))\n",
    "    outliers_pagevisits = np.array(outliers_pagevisits).tolist()\n",
    "    z1 = np.abs(stats.zscore(df.totalvisits))\n",
    "    threshold = 5\n",
    "    outliers_totalvisits =(np.where(z1 > 3))\n",
    "    outliers_totalvisits = np.array(outliers_totalvisits).tolist()\n",
    "    #combine both lists to the drop these rows\n",
    "    outliers = [*outliers_totalvisits, *outliers_pagevisits]\n",
    "    for i in outliers:\n",
    "        df.drop(df.index[[i]], inplace = True)\n",
    "    #df.drop(columns = 'lead_number', inplace =True) #--> will use it later to give the score based on this number\n",
    "    \n",
    "    \n",
    "    #display(df.isnull().sum())\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a8e8e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_data(df):\n",
    "    lead_numerical = df.select_dtypes(include=np.number)\n",
    "    lead_categorical = df.select_dtypes(include=np.object)\n",
    "    dummies = pd.get_dummies(data = lead_categorical, drop_first=True)\n",
    "    #dropping target value from lead_numerical\n",
    "    lead_numericals = lead_numerical.drop(columns= \"converted\")\n",
    "    lead_numericals = lead_numerical.drop(columns= \"lead_number\")\n",
    "    \n",
    "    #scaling numerical features \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(lead_numericals) #z score \n",
    "    lead_numericals_scaled = scaler.transform(lead_numericals) #gives an array\n",
    "    lead_numericals_scaled = pd.DataFrame(lead_numericals_scaled, columns = lead_numericals.columns) #transform it to a df\n",
    "    #hstack scaled numerical & encoded categorical\n",
    "    lead_df_numbers = pd.DataFrame(np.hstack([dummies, lead_numericals_scaled]))\n",
    "\n",
    "    #saving column names in a list to append it\n",
    "    column_names = [*dummies.columns.tolist(),*lead_numericals_scaled.columns.tolist()]\n",
    "    \n",
    "    lead_df_numbers.set_axis(column_names,axis =1,inplace=True)\n",
    "    #dropping high correlation column\n",
    "    lead_df_numbers.drop(columns='lead_source_Facebook',inplace=True)\n",
    "    X = lead_df_numbers\n",
    "    y = df.converted\n",
    "    return lead_df_numbers\n",
    "    return X\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf2543b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
